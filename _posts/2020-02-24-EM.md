---
layout: post
title:  "EM algorithm"
use_math: true
comments: true
---
# EM (Expectation and Maximization)
## Inference with Latent Variables
- Difference between classification and clustering
	- classification (supervised): observed variable X와 parameter의 관계 정의
	- clustering (unsupervised): 관측되지 않는 Latent (hidden) variable이 존재하는 probabilistic model의 MLE 또는 MAP를 풀기 위해 사용
- Let's say
	- $X$: observed variable
	- $Z$: hidden (latent) variable
	- $\theta$: parameters for distribution
	- $P(X|\theta)=\sum_ZP(X,Z|\theta)\rightarrow \ln\{\sum_ZP(X,Z|\theta)\}$
		- Z에 대해서 marginalize out (summation)하는 term이 log안에 있어 optimization하기 어려움
- $\text{Z와 }\theta$를 모두 구하기 위해서 두 value를 반복적인 방법으로 최적화하기 위한 방법으로 EM알고리즘을 사용

## Probability Decomposition
log-likelihood를 구하기 위해 아래의 식을 생각해 볼 수있다.

$l(\theta)=\ln{P(X|\theta)}=\ln\{\sum_ZP(X,Z|\theta)\}=\ln\{\sum_Zq(Z)\frac{P(X,Z|\theta)}{q(Z)}\}$

